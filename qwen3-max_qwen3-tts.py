# qwen_tts_integration.py
import os
import asyncio
import logging
import time
import sys
from dotenv import load_dotenv
from dashscope import Generation
from dashscope.api_entities.dashscope_response import Role
import pyaudio
import wave
import threading
from queue import Queue

from tts_realtime_client import TTSRealtimeClient, SessionMode

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()
API_KEY = os.getenv("DASHSCOPE_API_KEY")
TTS_URL = "wss://dashscope.aliyuncs.com/api-ws/v1/realtime?model=qwen3-tts-flash-realtime"

if not API_KEY:
    raise ValueError("âŒ DASHSCOPE_API_KEY environment variable is not set. Please create a .env file with your API key.")

# éŸ³é¢‘æ’­æ”¾å‚æ•°
AUDIO_SAMPLE_RATE = 24000
AUDIO_FORMAT = pyaudio.paInt16
AUDIO_CHANNELS = 1
AUDIO_BUFFER_SIZE = 2048

# å…¨å±€å˜é‡
audio_chunks = []
audio_pyaudio = None
audio_stream = None
text_queue = Queue()
is_playing = False

# æ—¶é—´ç»Ÿè®¡å˜é‡
text_start_time = None
first_token_time = None  # æ–°å¢ï¼šè®°å½•ç¬¬ä¸€ä¸ªtokenç”Ÿæˆæ—¶é—´
last_token_time = None  # æ–°å¢ï¼šè®°å½•ä¸Šä¸€ä¸ªtokençš„æ—¶é—´
first_audio_time = None
first_audio_logged = False

def audio_callback(audio_bytes: bytes):
    """TTSéŸ³é¢‘å›è°ƒå‡½æ•°ï¼šå®æ—¶æ’­æ”¾å¹¶ç¼“å­˜éŸ³é¢‘æ•°æ®"""
    print(f"DEBUG: Audio callback triggered with {len(audio_bytes)} bytes")
    global audio_stream, first_audio_time, first_audio_logged, text_start_time, first_token_time
    
    # ç¼“å­˜éŸ³é¢‘æ•°æ®ï¼ˆæ— è®ºæ˜¯å¦èƒ½æ’­æ”¾ï¼‰
    audio_chunks.append(audio_bytes)
    logging.info(f"Received audio chunk: {len(audio_bytes)} bytes")

    # å°è¯•æ’­æ”¾éŸ³é¢‘
    if audio_stream is not None:
        try:
            audio_stream.write(audio_bytes)
        except Exception as exc:
            logging.error(f"PyAudio playback error: {exc}")
            # å³ä½¿æ’­æ”¾å¤±è´¥ä¹Ÿè¦ç»§ç»­ç¼“å­˜æ•°æ®

    # è®°å½•é¦–æ¬¡éŸ³é¢‘åˆ°è¾¾æ—¶é—´å¹¶è®¡ç®—é¦–åŒ…å»¶è¿Ÿ
    if not first_audio_logged and text_start_time is not None:
        first_audio_time = time.time()
        latency = (first_audio_time - text_start_time) * 1000  # æ¯«ç§’
        logging.info(f"[METRIC] Time to first audio: {latency:.2f} ms")
        
        # å¦‚æœå·²ç»è®°å½•äº†ç¬¬ä¸€ä¸ªtokençš„æ—¶é—´ï¼Œåˆ™è®¡ç®—tokenåˆ°éŸ³é¢‘æ’­æ”¾çš„æ—¶é—´é—´éš”
        if first_token_time is not None:
            token_to_audio_latency = (first_audio_time - first_token_time) * 1000  # æ¯«ç§’
            logging.info(f"[METRIC] Time from first token to first audio: {token_to_audio_latency:.2f} ms")
        
        first_audio_logged = True

def save_audio_to_file(filename: str = "qwen_tts_output.wav", sample_rate: int = 24000) -> bool:
    """ä¿å­˜éŸ³é¢‘æ•°æ®åˆ°æ–‡ä»¶"""
    if not audio_chunks:
        logging.warning("No audio data to save")
        return False
    try:
        audio_data = b"".join(audio_chunks)
        with wave.open(filename, 'wb') as wav_file:
            wav_file.setnchannels(AUDIO_CHANNELS)
            wav_file.setsampwidth(2)
            wav_file.setframerate(sample_rate)
            wav_file.writeframes(audio_data)
        logging.info(f"Audio saved to: {filename}")
        return True
    except Exception as exc:
        logging.error(f"Failed to save audio: {exc}")
        return False




async def generate_text(prompt: str):
    """ä½¿ç”¨Qwen3-Maxæ¨¡å‹æµå¼ç”Ÿæˆæ–‡æœ¬"""
    global text_start_time, first_token_time, last_token_time

    # æ˜¾å¼è®¾ç½®APIå¯†é’¥
    import dashscope
    dashscope.api_key = API_KEY
    
    messages = [
        {'role': Role.SYSTEM, 'content': 'ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹'},
        {'role': Role.USER, 'content': prompt}
    ]
    
    text_start_time = time.time()
    full_response = ""
    
    try:
        response = Generation.call(
            model="qwen3-max",
            messages=messages,
            result_format='message',
            stream=True,
            incremental_output=True
        )
        
        print("ğŸ¤– AIåŠ©æ‰‹: ", end="", flush=True)
        
        for chunk in response:
            if chunk.status_code == 200:
                content = chunk.output.choices[0].message.content
                if content:
                    current_time = time.time()
                    
                    # è®°å½•ç¬¬ä¸€ä¸ªtokençš„æ—¶é—´
                    if first_token_time is None:
                        first_token_time = current_time
                        latency = (first_token_time - text_start_time) * 1000  # æ¯«ç§’
                        logging.info(f"[METRIC] Time to first token: {latency:.2f} ms")
                    # è®°å½•åç»­tokençš„æ—¶é—´é—´éš”
                    elif last_token_time is not None:
                        token_interval = (current_time - last_token_time) * 1000  # æ¯«ç§’
                        logging.info(f"[METRIC] Time since last token: {token_interval:.2f} ms")
                    
                    # æ›´æ–°ä¸Šä¸€ä¸ªtokençš„æ—¶é—´
                    last_token_time = current_time
                    
                    full_response += content
                    # å®æ—¶æ‰“å°è¾“å‡º
                    print(content, end="", flush=True)
                    # å°†ç”Ÿæˆçš„æ–‡æœ¬æ”¾å…¥é˜Ÿåˆ—ä¾›TTSæ¶ˆè´¹
                    text_queue.put(content)
                    # æ·»åŠ å°å»¶è¿Ÿä»¥ç¡®ä¿TTSèƒ½åŠæ—¶å¤„ç†
                    await asyncio.sleep(0.01)
            else:
                print(f"\nâŒ æ–‡æœ¬ç”Ÿæˆé”™è¯¯: {chunk.code} {chunk.message}")
                break
                
        print()  # æ¢è¡Œ
        
        # ç¡®ä¿æ‰€æœ‰æ–‡æœ¬éƒ½å·²å¤„ç†å®Œåå†å‘é€ç»“æŸæ ‡è®°
        await asyncio.sleep(0.2)
        # æ–‡æœ¬ç”Ÿæˆå®Œæˆåå‘é€ç»“æŸæ ‡è®°
        text_queue.put(None)
        print("ğŸ“ æ–‡æœ¬ç”Ÿæˆå®Œæˆ")
        logging.info("Text generation completed")
        
    except Exception as e:
        print(f"\nâŒ æ–‡æœ¬ç”Ÿæˆå¼‚å¸¸: {e}")
        logging.error(f"Text generation error: {e}")
        text_queue.put(None)  # ç¡®ä¿å‘é€ç»“æŸæ ‡è®°


# æ›¿æ¢ text_to_speech_producer å‡½æ•°ä¸­çš„ä»£ç 
async def text_to_speech_producer(client: TTSRealtimeClient):
    """ä»æ–‡æœ¬é˜Ÿåˆ—ä¸­è·å–æ–‡æœ¬å¹¶å‘é€ç»™TTSå®¢æˆ·ç«¯"""
    print("ğŸ§ TTSç”Ÿäº§è€…å·²å¯åŠ¨")
    text_count = 0
    
    while True:
        try:
            # ä½¿ç”¨éé˜»å¡æ–¹å¼è·å–é˜Ÿåˆ—å†…å®¹
            text = text_queue.get(timeout=30)  # å¢åŠ è¶…æ—¶æ—¶é—´
            if text is None:
                # æ–‡æœ¬ç”Ÿæˆå®Œæˆï¼Œç»“æŸä¼šè¯
                print("ğŸ“ æ–‡æœ¬æµç»“æŸï¼Œæ­£åœ¨ç»“æŸTTSä¼šè¯...")
                await client.finish_session()
                print("âœ… TTSä¼šè¯å·²ç»“æŸ")
                break
            else:
                text_count += 1
                print(f"ğŸ“¤ å‘é€ç¬¬{text_count}æ®µæ–‡æœ¬åˆ°TTS: {text[:50]}{'...' if len(text) > 50 else ''}")
                await client.append_text(text)
                # æ·»åŠ å°å»¶è¿Ÿä»¥é¿å…å‘é€è¿‡äºé¢‘ç¹
                await asyncio.sleep(0.05)
        except Exception as e:
            print(f"âš ï¸ TTSç”Ÿäº§è€…å¼‚å¸¸: {e}")
            # æ£€æŸ¥æ˜¯å¦æ˜¯è¿æ¥é—®é¢˜ï¼Œå¦‚æœæ˜¯åˆ™é€€å‡ºå¾ªç¯
            if "keepalive ping timeout" in str(e) or "connection closed" in str(e).lower():
                break
            # ä¸ç«‹å³é€€å‡ºï¼Œç»§ç»­ç­‰å¾…å¯èƒ½çš„æ–‡æœ¬
            await asyncio.sleep(0.1)
            # å¦‚æœé•¿æ—¶é—´æ²¡æœ‰æ–°æ–‡æœ¬ï¼Œå¯ä»¥è€ƒè™‘é€€å‡º
            continue
    
    print(f"ğŸ§ TTSç”Ÿäº§è€…å·²å®Œæˆï¼Œå…±å¤„ç† {text_count} æ®µæ–‡æœ¬")
    
    
async def run_integration_demo(prompt: str = None):
    """è¿è¡Œé›†æˆæ¼”ç¤ºï¼šæ–‡æœ¬ç”Ÿæˆ + TTS"""
    global audio_stream, text_start_time, first_audio_logged, audio_chunks, audio_pyaudio
    # é‡ç½®å…¨å±€çŠ¶æ€
    audio_chunks = []
    first_audio_logged = False
    text_start_time = None
    
    # é‡æ–°åˆå§‹åŒ– PyAudio
    if audio_pyaudio is not None:
        audio_pyaudio.terminate()
    audio_pyaudio = pyaudio.PyAudio()
    
    try:
        # åˆå§‹åŒ–éŸ³é¢‘æµ
        try:
            audio_stream = audio_pyaudio.open(
                format=AUDIO_FORMAT,
                channels=AUDIO_CHANNELS,
                rate=AUDIO_SAMPLE_RATE,
                output=True,
                frames_per_buffer=AUDIO_BUFFER_SIZE
            )
        except Exception as e:
            print(f"âš ï¸ éŸ³é¢‘è®¾å¤‡åˆå§‹åŒ–å¤±è´¥: {e}")
            # å¯ä»¥é€‰æ‹©ç»§ç»­è¿è¡Œä½†ä¸æ’­æ”¾éŸ³é¢‘ï¼Œæˆ–ä½¿ç”¨è™šæ‹Ÿè®¾å¤‡
            audio_stream = None

        # åˆå§‹åŒ–TTSå®¢æˆ·ç«¯
        tts_client = TTSRealtimeClient(
            base_url=TTS_URL,
            api_key=API_KEY,
            voice="Cherry",
            language_type="Chinese",
            mode=SessionMode.SERVER_COMMIT,
            audio_callback=audio_callback
        )

        session_start = time.time()

        # è¿æ¥åˆ°TTSæœåŠ¡
        print("ğŸ”Œ æ­£åœ¨è¿æ¥åˆ°TTSæœåŠ¡...")
        await tts_client.connect()
        print("âœ… TTSæœåŠ¡è¿æ¥æˆåŠŸ")

        # å¯åŠ¨æ¶ˆæ¯å¤„ç†ä»»åŠ¡
        consumer_task = asyncio.create_task(tts_client.handle_messages())

        # ç¨å¾®ç­‰å¾…ç¡®ä¿è¿æ¥å»ºç«‹
        await asyncio.sleep(0.1)

        # è·å–ç”¨æˆ·è¾“å…¥
        if prompt is None:
            prompt = input("ğŸ’¬ è¯·è¾“å…¥æ‚¨çš„é—®é¢˜: ")

        print(f"ğŸ¤” æ­£åœ¨å¤„ç†é—®é¢˜: {prompt}")

        # å¯åŠ¨æ–‡æœ¬ç”Ÿæˆå’ŒTTSä»»åŠ¡
        text_generation_task = asyncio.create_task(generate_text(prompt))
        tts_producer_task = asyncio.create_task(text_to_speech_producer(tts_client))

        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        await asyncio.gather(text_generation_task, tts_producer_task, return_exceptions=True)

        # ç­‰å¾…ä¸€æ®µæ—¶é—´ç¡®ä¿æ‰€æœ‰éŸ³é¢‘æ’­æ”¾å®Œæ¯•
        print("â³ ç­‰å¾…éŸ³é¢‘æ’­æ”¾å®Œæˆ...")
        await asyncio.sleep(5)
    
    except Exception as e:
        print(f"âŒ è¿è¡Œæ—¶é”™è¯¯: {e}")
    finally:
        # ç¡®ä¿èµ„æºæ¸…ç†
        if 'tts_client' in locals():
            await tts_client.close()
        if 'consumer_task' in locals():
            consumer_task.cancel()

        # æ¸…ç†éŸ³é¢‘èµ„æº
        if audio_stream is not None:
            audio_stream.stop_stream()
            audio_stream.close()
        if audio_pyaudio is not None:
            audio_pyaudio.terminate()

        total_time = (time.time() - session_start) * 1000  # æ¯«ç§’
        logging.info(f"[METRIC] Total session time: {total_time:.2f} ms")

        if not first_audio_logged and text_start_time is not None:
            logging.warning("[METRIC] No audio received at all!")

        # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
        os.makedirs("outputs", exist_ok=True)
        save_audio_to_file(os.path.join("outputs", "qwen_tts_integration_output.wav"))

def interactive_mode():
    """äº¤äº’å¼æ¨¡å¼"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s [%(levelname)s] %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    print("ğŸš€ å¯åŠ¨ Qwen æ–‡æœ¬ç”Ÿæˆ + TTS äº¤äº’å¼æ¼”ç¤º...")
    print("è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡ºç¨‹åº\n")
    
    while True:
        try:
            prompt = input("ğŸ’¬ è¯·è¾“å…¥æ‚¨çš„é—®é¢˜: ").strip()
            if prompt.lower() in ['quit', 'exit']:
                print("ğŸ‘‹ å†è§!")
                break
            
            if prompt:
                asyncio.run(run_integration_demo(prompt))
                print("-" * 50)  # åˆ†éš”çº¿
            else:
                print("âš ï¸  è¯·è¾“å…¥æœ‰æ•ˆé—®é¢˜")
                
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­ï¼Œå†è§!")
            break
        except Exception as e:
            print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")

def main():
    # é…ç½®æ—¥å¿—ï¼ˆå‡å°‘å¹²æ‰°ï¼‰
    logging.basicConfig(
        level=logging.INFO,  # åªæ˜¾ç¤ºè­¦å‘ŠåŠä»¥ä¸Šçº§åˆ«æ—¥å¿—
        format='%(asctime)s [%(levelname)s] %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    if len(sys.argv) > 1:
        # å‘½ä»¤è¡Œå‚æ•°æ¨¡å¼
        prompt = " ".join(sys.argv[1:])
        logging.getLogger().setLevel(logging.INFO)  # æ¢å¤è¯¦ç»†æ—¥å¿—
        asyncio.run(run_integration_demo(prompt))
    else:
        # äº¤äº’å¼æ¨¡å¼
        interactive_mode()

if __name__ == "__main__":
    main()